env_config:
    dir_name: "T-LSO" # Save runs here. (Overrides the very first line of the model config.)
    timesteps_total: 500000 # Stop time in steps. (Overrides model config.)
    num_workers: 5 # (Overrides model config.)
    num_envs_per_worker: 2 # (Overrides model config.)
    num_gpus: 1 # (Overrides model config.)
    check_up: 1 # Observation for check / noise pointed up
    check_down: -1
    maze_length_upper_bound: null
    pos_enc: False
    wave_encoding_len: null # Can be null for no not wave-based encoding
    task_switch_after: null # Override some settings to switch from short term task to long after x steps (or null)
    intermediate_checks: True
    intermediate_indicators: True # Whether there are intermediate indicators. (Even if no checks, will increase action dimension)
    reset_intermediate_indicators: True # whether the intermediate indicators change from episode to episode
    per_step_reset: True
    num_indicators_components: 1 # The length of the intermediate indicators
    frac_correct_components_for_check: 1 # The fraction of the components needed to be correct to move to next location (rounded up)
    final_intermediate_indicator: True # Whether or not there is an intermediate indicator at then end
    check_reward: 0.1
    reward_per_correct_component: False # Whether to give check_reward * the fraction correct
    allow_left: False
    force_final_decision: False # Whether to force the agent to move up or down at end
    force_right: False # Whether to force the agent to move right (not at end and not for checks)
    timeout: 150 # Max steps allowed or null
    timeout_reward: 0
    maze_length: 100
    indicator_pos: 1
    flipped_indicator_pos: null # can be null for no duplicate flipped indicator
    correlated_indicator_pos: 2 # can be null for no correlated indicator
    success_reward: 4.0
    fail_reward: -3.0
    persistent_reward: 0.0 # Reward given per time step
        